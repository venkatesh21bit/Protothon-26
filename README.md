# Nidaan.ai â€” AI Clinical Documentation System

<div align="center">

![Nidaan.ai](https://img.shields.io/badge/Nidaan.ai-Clinical%20Intelligence-0066cc?style=for-the-badge)
![Version](https://img.shields.io/badge/version-1.0.0-28a745?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.11-3776ab?style=for-the-badge&logo=python)
![Next.js](https://img.shields.io/badge/Next.js-14-black?style=for-the-badge&logo=next.js)
![Gemini](https://img.shields.io/badge/Gemini-3--flash-4285f4?style=for-the-badge&logo=google)
![License](https://img.shields.io/badge/license-MIT-blue?style=for-the-badge)

**Transform wasted time in the waiting room into life-saving clinical data**

[Architecture](#-system-architecture) â€¢ [AI Pipeline](#-ai-pipeline) â€¢ [API Reference](#-api-reference) â€¢ [Database Schema](#-database-schema) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage)

</div>

---

## Overview

**Nidaan** (Hindi: à¤¨à¤¿à¤¦à¤¾à¤¨ â€” "Diagnosis") converts spoken vernacular patient descriptions into structured SOAP notes, differential diagnoses, and red-flag alerts â€” before the patient even walks into the consultation room.

### The Problem
- Patients waste 30â€“60 minutes in waiting rooms filling paper forms
- Language barriers isolate rural patients from English-trained doctors
- Manual history-taking consumes 40% of consultation time
- Critical symptoms are missed through poor communication

### The Solution
1. **Multilingual Active Intake** â€” patients speak naturally in Tamil, Hindi, Telugu, Marathi, Bengali, Kannada, Malayalam, Gujarati or English
2. **Gemini-Powered STT** â€” audio streamed inline to `gemini-3-flash-preview`; no third-party transcription service needed
3. **Clinical RAG Chain** â€” four sequential Gemini prompts produce a SOAP note, differential diagnosis, and red-flag matrix
4. **Doctor Pre-Brief** â€” structured summary is waiting in the doctor's dashboard before they call the patient in

---

## System Architecture

### Top-level Component Map

```mermaid
graph TD
    subgraph Client["Client Layer"]
        PWA[Patient PWA\nNext.js 14 Â· App Router]
        DOC[Doctor Dashboard\nNext.js 14]
        NURSE[Nurse Station\nNext.js 14]
        ADMIN[Admin Panel\nNext.js 14]
    end

    subgraph API["API Layer  â€”  FastAPI 0.104 Â· Python 3.11 Â· uvicorn --reload"]
        AUTH["/auth\nJWT HS256"]
        PAT["/patients\nChat Â· STT Â· Intake FSM"]
        DOC_R["/doctors\nVisits Â· SOAP"]
        TRIAGE["/triage\nScore Â· Alert"]
        APPT["/appointments\nCRUD"]
        WS["/ws\nWebSocket Hub"]
        AGENTS["/ai-agents\nOrchestrator"]
    end

    subgraph AI["AI Layer  â€”  Google Gemini gemini-3-flash-preview"]
        CHAT_G["Intake Chat\nConversational FSM\nmax_output_tokens=1200"]
        STT_G["Inline Audio STT\nPart.from_bytes()\nWebM Â· OGG Â· WAV Â· MP3"]
        CHAIN["MedicalRAGChain\n4 sequential prompts"]
        ORCH["AgentOrchestrator\n4 async sub-agents"]
        TRIAGE_E["TriageEngine\nKeyword scoring + NLU"]
    end

    subgraph DATA["Data Layer"]
        PG[(PostgreSQL 15\ntriage_cases JSONB\nsurveys JSONB)]
        REDIS[(Redis 7\nRate limits Â· WS pub/sub)]
        FS[(Local Filesystem\naudio uploads)]
    end

    subgraph NOTIFY["Notification Layer"]
        SMTP[Gmail SMTP TLS\nNurse HIGH-severity alerts]
        WS_OUT[WebSocket broadcast\nReal-time dashboard push]
    end

    PWA & DOC & NURSE & ADMIN -->|HTTPS REST + WS| API
    PAT -->|generate_content| CHAT_G & STT_G
    DOC_R -->|on demand| CHAIN
    TRIAGE -->|score| TRIAGE_E
    AGENTS -->|coordinates| ORCH
    CHAIN & ORCH & TRIAGE_E --> PG
    TRIAGE_E -->|HIGH alert| SMTP
    WS -->|pub/sub| REDIS & WS_OUT
    API -->|asyncpg pool size=10 overflow=20| PG
    AUTH -->|bcrypt verify| PG
```

---

## Request Lifecycles

### 1 Â· Patient Intake Chat

```mermaid
sequenceDiagram
    participant Browser
    participant NextJS as Next.js :3000
    participant FastAPI as FastAPI :8000
    participant Gemini as Gemini API
    participant PG as PostgreSQL

    Browser->>NextJS: POST /patients/chat {message, history, language}
    NextJS->>FastAPI: Bearer JWT Â· proxy
    FastAPI->>FastAPI: get_current_user() â€” decode HS256 JWT
    FastAPI->>FastAPI: _get_or_create_collected(user_id)
    FastAPI->>FastAPI: _next_missing_field(collected) â†’ next_field
    FastAPI->>FastAPI: _build_system_prompt(collected, turn, next_field)
    FastAPI->>FastAPI: sanitise history â€” strip <data>â€¦</data> blocks
    FastAPI->>Gemini: generate_content(model, system_instruction, contents[])
    Note over Gemini: max_output_tokens=1200
    Gemini-->>FastAPI: raw_text
    FastAPI->>FastAPI: _extract_data_json() â†’ merge into collected dict
    FastAPI->>FastAPI: re.sub strip <data> from visible_text
    FastAPI->>PG: UPSERT triage_cases SET data = jsonb_set(â€¦)
    FastAPI-->>Browser: {response, collected_symptoms, severity_assessment}
```

### 2 Â· Voice STT Pipeline

```mermaid
sequenceDiagram
    participant Mic as Browser Mic
    participant WA as Web Audio API
    participant MR as MediaRecorder
    participant NextJS as Next.js
    participant FastAPI as FastAPI
    participant Gemini as Gemini API

    Mic->>WA: getUserMedia({channelCount:1, sampleRate:16000, echoCancellation:true})
    WA->>WA: AudioContext â†’ AnalyserNode fftSize=256
    Note over WA: rAF loop: getByteFrequencyData() â†’ mean/255 â†’ audioLevel 0â€¥1
    WA->>MR: MediaRecorder(stream, mimeType='audio/webm;codecs=opus')
    MR->>MR: start(timeslice=250ms) â†’ ondataavailable chunks[]
    Note over MR: User taps Stop orb
    MR->>MR: stop() â†’ onstop fires â†’ Blob(chunks)
    MR->>NextJS: Blob size check (< 500 B â†’ abort)
    NextJS->>FastAPI: POST /api/v1/patients/voice-transcribe\nmultipart: audio=<blob> language=ta-IN
    FastAPI->>FastAPI: detect MIME from content_type
    FastAPI->>Gemini: generate_content([prompt, Part.from_bytes(bytes, mime)])
    Note over Gemini: Inline audio â€” max 20 MB\nFormats: WebM OGG WAV MP3 AAC FLAC
    Gemini-->>FastAPI: transcript (Tamil / Hindi / etc.)
    FastAPI-->>NextJS: {transcript, language}
    NextJS->>NextJS: setChatInput(transcript) or processVoiceInput(transcript)
```

### 3 Â· SOAP Note Generation

```mermaid
sequenceDiagram
    participant Dashboard as Doctor Dashboard
    participant FastAPI as FastAPI
    participant RAGChain as MedicalRAGChain
    participant Gemini as Gemini API
    participant PG as PostgreSQL

    Dashboard->>FastAPI: GET /api/v1/doctors/visits/{id}
    FastAPI->>PG: SELECT data JSONB FROM triage_cases WHERE id=?
    alt soap_note absent in JSONB
        FastAPI->>RAGChain: generate_soap_note(transcript, symptoms, language)
        RAGChain->>Gemini: Chain 1 â€” CLINICAL_TRANSLATION_PROMPT
        Gemini-->>RAGChain: medical_english
        RAGChain->>Gemini: Chain 2 â€” SOAP_NOTE_GENERATION_PROMPT
        Gemini-->>RAGChain: {subjective, objective, assessment, plan}
        RAGChain->>Gemini: Chain 3 â€” DIFFERENTIAL_DIAGNOSIS_PROMPT
        Gemini-->>RAGChain: [{condition, probability, reasoning, urgency}]
        RAGChain->>Gemini: Chain 4 â€” RED_FLAG_DETECTION_PROMPT
        Gemini-->>RAGChain: [{flag, severity, recommended_action}]
        FastAPI->>PG: UPDATE triage_cases SET data = jsonb_set(â€¦soap_noteâ€¦)
    end
    FastAPI-->>Dashboard: VisitDetailResponse
```

---

## AI Pipeline

### Conversational Intake â€” Finite State Machine

The intake is a **6-field state machine** running over `MAX_TURNS = 12` turns:

```
INTAKE_FIELDS = [
  "symptoms",            # chief complaint
  "duration",            # hours / days / weeks
  "severity",            # 1â€“10 pain scale
  "location",            # body part / side / region
  "associated_symptoms", # accompanying symptoms
  "medical_history",     # known conditions + current medications
]

INTAKE_THRESHOLD = 4    # minimum fields before triage is triggered
MAX_TURNS        = 12   # forces wrap-up summary at turn 12
```

Per-turn logic:

```
_get_or_create_collected(user_id)
  â””â”€ _next_missing_field(collected)      â†’ next_field (first empty field)
       â””â”€ _build_system_prompt(...)
            â”œâ”€ LANGUAGE RULE: reply in same language as patient
            â”œâ”€ INFORMATION ALREADY COLLECTED block  (prevents re-asking)
            â”œâ”€ NEXT ACTION: field-specific question script
            â””â”€ 8 ABSOLUTE FORBIDDEN rules
                 1. Never diagnose or speculate
                 2. Never ask for already-known info
                 3. Ask one question per turn
                 4. No medical jargon to patient
                 5. Graceful off-topic redirect
                 6. Warm, culturally sensitive tone
                 7. NEVER re-ask info already listed
                 8. ALWAYS write complete sentences
  â””â”€ sanitise_history()
       â””â”€ re.sub(r"\s*<data>[\s\S]*?(?:</data>|$)", "", msg.content)
  â””â”€ Gemini generate_content  (max_output_tokens=1200)
  â””â”€ _extract_data_json(raw)  â†’ parse JSON in <data>{â€¦}</data>
  â””â”€ visible_text = re.sub(r"\s*<data>[\s\S]*$", "", raw)
  â””â”€ merge extracted fields into collected dict
  â””â”€ UPSERT triage_cases JSONB
```

### MedicalRAGChain â€” 4-Step Gemini Pipeline

| # | Method | Prompt Template | Output Schema |
|---|--------|-----------------|---------------|
| 1 | `translate_to_medical_english` | `CLINICAL_TRANSLATION_PROMPT` | `str` â€” medical English |
| 2 | `generate_soap_note` | `SOAP_NOTE_GENERATION_PROMPT` | `{subjective, objective, assessment, plan}` |
| 3 | `generate_differential_diagnosis` | `DIFFERENTIAL_DIAGNOSIS_PROMPT` | `[{condition, probability, reasoning, urgency}]` |
| 4 | `detect_red_flags` | `RED_FLAG_DETECTION_PROMPT` | `[{flag, severity, recommended_action}]` |

All steps use `google-genai` SDK (`genai.Client.models.generate_content`). Falls back to deterministic mock responses when `GEMINI_API_KEY` is absent.

### TriageEngine â€” Rule + NLU Severity Scoring

```
Input: symptom list + free-text description

Step 1 â€” Keyword scan (60+ terms)
  RED_FLAG_SYMPTOMS dict  â†’  each maps to HIGH / MEDIUM / LOW
  e.g. "chest pain" â†’ HIGH, "palpitations" â†’ MEDIUM, "nausea" â†’ LOW

Step 2 â€” Composite severity score
  base_score   = max(keyword_severity_values)
  count_boost  = len(symptoms) Ã— 0.10
  duration_mod = 0.0 (hours) | 0.1 (days) | 0.2 (weeks+)
  age_mod      = 0.15 if age > 60 else 0.0
  final        = clamp(base_score + count_boost + duration_mod + age_mod,
                       LOW, HIGH)

Step 3 â€” NLU entity enrichment (nlu_processor.py)
  Entity types: body_part, temporal, medication, negation
  Signal amplifiers: "severe", "unbearable", "worst ever" â†’ +1 severity tier

Step 4 â€” Persist + alert
  triage_cases.severity_score = HIGH | MEDIUM | LOW
  triage_cases.status         = 'pending'
  IF HIGH â†’ email_service.send_nurse_alert()  (Gmail SMTP port 587 TLS)
```

### AgentOrchestrator â€” 5-Stage Multi-Agent Workflow

```mermaid
flowchart LR
    A([Appointment\nCreated]) --> B
    B["Stage 1\nSymptomAnalyzerAgent\nurgency Â· severity_score\npossible_conditions[]"] --> C
    C["Stage 2\nAppointmentSchedulerAgent\nauto-schedule slot\nbased on urgency tier"] --> D
    D["Stage 3\nTriageAgent\nER Â· GP Â· Specialist\nrouting decision"] --> E
    E["Stage 4\nFollowUpAgent\ncare plan + reminders\nmedication notes"] --> F
    F([Workflow Result\nstages[] + final_status\nworkflow_id + timestamps])
```

---

## Database Schema

```sql
-- One row per patient visit / triage encounter
CREATE TABLE triage_cases (
    id             TEXT PRIMARY KEY,          -- UUID v4
    patient_id     TEXT NOT NULL,             -- references users table
    severity_score TEXT NOT NULL DEFAULT 'LOW',   -- HIGH | MEDIUM | LOW
    status         TEXT NOT NULL DEFAULT 'pending', -- pending | in_progress | completed
    nurse_alerted  BOOLEAN NOT NULL DEFAULT FALSE,
    data           JSONB NOT NULL DEFAULT '{}',  -- entire encounter payload
    created_at     TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at     TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
CREATE INDEX idx_triage_cases_patient         ON triage_cases (patient_id);
CREATE INDEX idx_triage_cases_severity_status ON triage_cases (severity_score, status);

-- Survey form responses
CREATE TABLE surveys (
    id             TEXT PRIMARY KEY,
    patient_id     TEXT NOT NULL,
    appointment_id TEXT,
    status         TEXT NOT NULL DEFAULT 'pending',
    data           JSONB NOT NULL DEFAULT '{}',
    created_at     TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at     TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
CREATE INDEX idx_surveys_patient     ON surveys (patient_id);
CREATE INDEX idx_surveys_appointment ON surveys (appointment_id);
```

**`triage_cases.data` JSONB shape:**

```json
{
  "patient_name": "Ravi Kumar",
  "language": "ta-IN",
  "collected": {
    "symptoms": ["chest pain", "shortness of breath"],
    "duration": "2 days",
    "severity": "8",
    "location": "left chest, radiates to left arm",
    "associated_symptoms": ["nausea", "diaphoresis"],
    "medical_history": ["hypertension", "aspirin 75mg daily"]
  },
  "soap_note": {
    "subjective":  "Patient reports 2-day history of chest painâ€¦",
    "objective":   "Vital signs pending. Patient appears distressed.",
    "assessment":  "Likely ACS given risk factors and symptom pattern.",
    "plan":        "Immediate ECG, troponin, cardiology referral."
  },
  "differential_diagnosis": [
    {"condition": "Acute Coronary Syndrome", "probability": "HIGH",
     "reasoning": "Chest pain with radiation, diaphoresis, hypertension"},
    {"condition": "Unstable Angina",         "probability": "MEDIUM",
     "reasoning": "Exertional component not yet confirmed"}
  ],
  "red_flags": [
    {"flag": "chest pain with arm radiation",
     "severity": "CRITICAL",
     "recommended_action": "Immediate ECG + troponin; do not delay"}
  ],
  "conversation_turns": 7
}
```

---

## Authentication & Security

```mermaid
sequenceDiagram
    participant Client
    participant FastAPI
    participant BCrypt
    participant PG as PostgreSQL

    Client->>FastAPI: POST /api/v1/auth/login {email, password}
    FastAPI->>PG: SELECT hashed_password, role FROM users WHERE email=?
    FastAPI->>BCrypt: verify(plain, hashed)  â€” cost factor 12
    BCrypt-->>FastAPI: True / False
    FastAPI->>FastAPI: jwt.encode({sub, role, exp: +24h}, HS256)
    FastAPI-->>Client: {access_token, token_type:"bearer"}

    Note over Client,FastAPI: All subsequent requests
    Client->>FastAPI: Authorization: Bearer <token>
    FastAPI->>FastAPI: jwt.decode(token) â†’ {sub, role, exp}
    FastAPI->>FastAPI: get_current_user() â†’ injects user dict
```

| Parameter | Value |
|-----------|-------|
| Algorithm | HS256 |
| Token lifetime | 24 h (configurable) |
| Password hashing | BCrypt cost=12 |
| Transport (prod) | TLS 1.3 |
| Rate limiting | 60 req/min per IP via Redis |
| CORS | configurable origin allow-list |

---

## API Reference

### Patient Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `POST` | `/api/v1/patients/chat` | Stateful intake chat â€” FSM-driven, multi-turn |
| `POST` | `/api/v1/patients/voice-transcribe` | Gemini inline audio STT (multipart) |
| `POST` | `/api/v1/patients/reset` | Reset conversation state |
| `GET`  | `/api/v1/patients/` | List patients (admin/nurse) |
| `POST` | `/api/v1/patients/` | Register new patient |

**`POST /api/v1/patients/chat`**
```jsonc
// Request
{
  "message": "à®¨à¯‡à®±à¯à®±à¯ à®‡à®°à®µà®¿à®²à®¿à®°à¯à®¨à¯à®¤à¯ à®®à®¾à®°à¯à®ªà®¿à®²à¯ à®µà®²à®¿ à®‰à®³à¯à®³à®¤à¯",
  "conversation_history": [
    {"role": "assistant", "content": "à®µà®£à®•à¯à®•à®®à¯! à®¨à®¾à®©à¯ Nidaan AIâ€¦"}
  ],
  "language": "ta-IN"
}
// Response
{
  "response": "à®‰à®™à¯à®•à®³à¯ à®µà®²à®¿ à®à®¨à¯à®¤ à®‡à®Ÿà®¤à¯à®¤à®¿à®²à¯ à®…à®¤à®¿à®•à®®à®¾à®• à®‰à®³à¯à®³à®¤à¯?",
  "collected_symptoms": ["chest pain"],
  "severity_assessment": "MEDIUM"
}
```

**`POST /api/v1/patients/voice-transcribe`**
```
Content-Type: multipart/form-data
audio:    <binary â€” WebM / OGG / WAV / MP3 / AAC / FLAC>  max 20 MB
language: ta-IN | hi-IN | te-IN | en-IN | â€¦
```
```json
{"transcript": "à®¨à¯‡à®±à¯à®±à¯ à®‡à®°à®µà®¿à®²à®¿à®°à¯à®¨à¯à®¤à¯ à®®à®¾à®°à¯à®ªà®¿à®²à¯ à®µà®²à®¿ à®‰à®³à¯à®³à®¤à¯", "language": "ta-IN"}
```

### Doctor Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `GET`  | `/api/v1/doctors/visits` | All pending / in-progress visits |
| `GET`  | `/api/v1/doctors/visits/{id}` | Visit detail â€” triggers SOAP generation if absent |
| `PUT`  | `/api/v1/doctors/visits/{id}` | Update visit status |
| `GET`  | `/api/v1/doctors/profile` | Doctor profile |

### Triage Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `POST` | `/api/v1/triage/assess` | Score symptoms, persist case, alert nurse if HIGH |
| `GET`  | `/api/v1/triage/cases` | List all triage cases |
| `GET`  | `/api/v1/triage/cases/{id}` | Single case detail |
| `POST` | `/api/v1/triage/voice` | Process voice triage recording |

### Admin & Agents

| Method | Path | Description |
|--------|------|-------------|
| `POST` | `/api/v1/ai-agents/process-appointment` | Trigger 5-stage agent workflow |
| `GET`  | `/api/v1/admin/stats` | Clinic-wide analytics |
| `GET`  | `/api/v1/health` | Service health check |

---

## Frontend Architecture

### Page Structure (Next.js 14 App Router)

```
apps/web/app/
â”œâ”€â”€ layout.tsx                    # RootLayout + Tailwind globals
â”œâ”€â”€ page.tsx                      # Root â†’ redirect by JWT role
â”œâ”€â”€ login/page.tsx                # Login form â†’ POST /auth/login
â”œâ”€â”€ register/page.tsx             # Patient registration
â”œâ”€â”€ patient/
â”‚   â”œâ”€â”€ page.tsx                  # â˜… Main patient interface
â”‚   â”‚                              #   Chat mode: stateful Gemini FSM
â”‚   â”‚                              #   Voice mode: MediaRecorder â†’ Gemini STT
â”‚   â”‚                              #              + browser TTS (speechSynthesis)
â”‚   â”œâ”€â”€ survey/                   # Pre-visit form
â”‚   â”œâ”€â”€ triage/                   # Result display
â”‚   â””â”€â”€ triage-enhanced/          # Animated triage result
â”œâ”€â”€ doctor/
â”‚   â”œâ”€â”€ dashboard/                # Visit queue + risk stratification
â”‚   â”œâ”€â”€ dashboard-enhanced/       # Real-time WS + charts
â”‚   â””â”€â”€ visit/[visitId]/          # SOAP + differential + red flags
â”œâ”€â”€ nurse/dashboard/              # Nurse alert queue
â””â”€â”€ admin/
    â”œâ”€â”€ dashboard/                # Clinic analytics
    â”œâ”€â”€ appointments/             # Appointment management
    â””â”€â”€ agents/                   # Agent workflow monitor
```

### State Management (Zustand â€” `lib/store.ts`)

```typescript
interface NidaanStore {
  // Auth slice
  user:  User | null
  token: string | null
  setAuth(user: User, token: string): void
  logout(): void

  // Doctor slice
  visits:      Visit[]
  activeVisit: Visit | null
  setVisits(v: Visit[]): void
  setActiveVisit(v: Visit): void

  // Patient slice
  triageCase: TriageCase | null
  setTriageCase(tc: TriageCase): void
}
```

### WebSocket Integration (`lib/useWebSocket.ts`)

```typescript
// ws://localhost:8000/api/v1/ws/{user_id}
// Message types dispatched by server:
//   visit_update   â†’ update visit in store
//   new_alert      â†’ toast notification
//   agent_progress â†’ render workflow stage UI
useWebSocket(userId, {
  onVisitUpdate: (visit) => store.setActiveVisit(visit),
  onAlert:       (alert) => toast(alert.message),
})
```

### Voice Recording Architecture

```
navigator.mediaDevices.getUserMedia
  â””â”€ AudioContext (16 kHz mono)
       â”œâ”€ AnalyserNode fftSize=256
       â”‚    â””â”€ rAF: getByteFrequencyData() â†’ mean(buf)/255 â†’ audioLevel
       â”‚         â””â”€ CSS: width = ${128 + audioLevelÃ—60}px  (live ring)
       â””â”€ MediaRecorder (audio/webm;codecs=opus, timeslice=250 ms)
            â””â”€ ondataavailable â†’ chunks.push(e.data)  (250 ms slices)
            â””â”€ onstop
                 â”œâ”€ Blob(chunks, {type: 'audio/webm;codecs=opus'})
                 â”œâ”€ size < 500 B â†’ abort (silence guard)
                 â””â”€ FormData â†’ POST /api/v1/patients/voice-transcribe
                      â””â”€ transcript â†’ setChatInput() or processVoiceInput()
```

---

## Infrastructure

### Docker Compose

```mermaid
graph LR
    subgraph Stack["docker-compose.yml"]
        WEB["web :3000\nNext.js 14 Â· Node 18-alpine\nnpm run dev Â· hot reload"]
        API["api :8000\nFastAPI Â· Python 3.11-slim\nuvicorn --reload"]
        PG["postgres :5433â†’5432\npostgres:15-alpine"]
        REDIS["redis :6380â†’6379\nredis:7-alpine"]
    end

    WEB -->|HTTP proxy| API
    API -->|asyncpg pool_size=10 max_overflow=20| PG
    API -->|aioredis| REDIS
```

| Service | Image | Host Port | Volume |
|---------|-------|-----------|--------|
| `web`     | Node 18-alpine      | 3000 | `./apps/web:/app` (hot reload) |
| `api`     | Python 3.11-slim    | 8000 | `./apps/api:/app` (uvicorn --reload) |
| `postgres`| postgres:15-alpine  | 5433 | `postgres-data` (named volume) |
| `redis`   | redis:7-alpine      | 6380 | `redis-data` (named volume) |

### Environment Variables

| Variable | Required | Default | Purpose |
|----------|----------|---------|---------|
| `GEMINI_API_KEY` | **Yes** | â€” | Google AI Studio key |
| `GEMINI_MODEL` | No | `gemini-3-flash-preview` | Model name |
| `DATABASE_URL` | **Yes** | â€” | asyncpg connection string |
| `REDIS_URL` | No | `redis://localhost:6379` | Redis connection |
| `JWT_SECRET` | **Yes (prod)** | `your-secret-keyâ€¦` | HS256 signing secret |
| `JWT_EXPIRATION_MINUTES` | No | `1440` (24 h) | Token lifetime |
| `SMTP_EMAIL` | No | â€” | Nurse alert sender |
| `SMTP_PASSWORD` | No | â€” | Gmail app password |
| `NURSE_STATION_EMAIL` | No | â€” | Alert recipient |
| `STORAGE_PATH` | No | `./uploads` | Audio file directory |
| `DEBUG` | No | `True` | Enable Swagger UI + SQL echo |

---

## Supported Languages

| Language | Code | Gemini Chat | Gemini STT |
|----------|------|-------------|-----------|
| Tamil | `ta-IN` | âœ… | âœ… |
| Hindi | `hi-IN` | âœ… | âœ… |
| Telugu | `te-IN` | âœ… | âœ… |
| Marathi | `mr-IN` | âœ… | âœ… |
| Bengali | `bn-IN` | âœ… | âœ… |
| Kannada | `kn-IN` | âœ… | âœ… |
| Malayalam | `ml-IN` | âœ… | âœ… |
| Gujarati | `gu-IN` | âœ… | âœ… |
| Punjabi | `pa-IN` | âœ… | âœ… |
| English | `en-IN` / `en-US` | âœ… | âœ… |

STT uses `types.Part.from_bytes(data=audio_bytes, mime_type=mime_type)` â€” the same `gemini-3-flash-preview` model handles both transcription and clinical reasoning with no additional service.

---

## Project Structure

```
nidaan/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/                               # FastAPI backend
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ app/
â”‚   â”‚       â”œâ”€â”€ main.py                    # App factory Â· lifespan events
â”‚   â”‚       â”œâ”€â”€ core/
â”‚   â”‚       â”‚   â”œâ”€â”€ config.py              # Pydantic Settings (env vars)
â”‚   â”‚       â”‚   â”œâ”€â”€ db.py                  # SQLAlchemy async engine + DDL
â”‚   â”‚       â”‚   â”œâ”€â”€ security.py            # JWT + BCrypt
â”‚   â”‚       â”‚   â””â”€â”€ exceptions.py          # Custom exception hierarchy
â”‚   â”‚       â”œâ”€â”€ api/v1/
â”‚   â”‚       â”‚   â”œâ”€â”€ router.py              # Top-level API router
â”‚   â”‚       â”‚   â”œâ”€â”€ auth.py                # Login / register
â”‚   â”‚       â”‚   â”œâ”€â”€ patients.py            # â˜… Chat FSM + Gemini STT
â”‚   â”‚       â”‚   â”œâ”€â”€ doctors.py             # Visit queue + SOAP
â”‚   â”‚       â”‚   â”œâ”€â”€ triage.py              # Triage assess + voice
â”‚   â”‚       â”‚   â”œâ”€â”€ appointments.py        # Appointment CRUD
â”‚   â”‚       â”‚   â”œâ”€â”€ ai_agents.py           # Agent workflow API
â”‚   â”‚       â”‚   â”œâ”€â”€ websocket.py           # WS hub + broadcast
â”‚   â”‚       â”‚   â””â”€â”€ admin.py               # Clinic stats
â”‚   â”‚       â”œâ”€â”€ schemas/
â”‚   â”‚       â”‚   â”œâ”€â”€ patient.py             # PatientCreate / Response
â”‚   â”‚       â”‚   â”œâ”€â”€ triage.py              # TriageCase schemas
â”‚   â”‚       â”‚   â””â”€â”€ medical.py             # SOAP / Differential models
â”‚   â”‚       â””â”€â”€ services/
â”‚   â”‚           â”œâ”€â”€ llm_engine/
â”‚   â”‚           â”‚   â”œâ”€â”€ chain.py           # MedicalRAGChain (4 Gemini calls)
â”‚   â”‚           â”‚   â””â”€â”€ prompts.py         # Prompt templates
â”‚   â”‚           â”œâ”€â”€ ai_agents/
â”‚   â”‚           â”‚   â”œâ”€â”€ orchestrator.py    # AgentOrchestrator
â”‚   â”‚           â”‚   â”œâ”€â”€ symptom_analyzer.py
â”‚   â”‚           â”‚   â”œâ”€â”€ appointment_scheduler.py
â”‚   â”‚           â”‚   â”œâ”€â”€ triage_agent.py
â”‚   â”‚           â”‚   â””â”€â”€ followup_agent.py
â”‚   â”‚           â”œâ”€â”€ ibm/
â”‚   â”‚           â”‚   â”œâ”€â”€ triage_engine.py   # Rule + NLU severity scoring
â”‚   â”‚           â”‚   â”œâ”€â”€ nlu_processor.py   # Entity extraction
â”‚   â”‚           â”‚   â””â”€â”€ email_service.py   # SMTP nurse alerts
â”‚   â”‚           â”œâ”€â”€ storage.py             # Filesystem audio storage
â”‚   â”‚           â””â”€â”€ seed_data.py           # Demo data seeder
â”‚   â””â”€â”€ web/                               # Next.js 14 frontend
â”‚       â”œâ”€â”€ app/                           # App Router pages
â”‚       â”œâ”€â”€ components/                    # Shared React components
â”‚       â””â”€â”€ lib/
â”‚           â”œâ”€â”€ api.ts                     # Typed fetch client
â”‚           â”œâ”€â”€ store.ts                   # Zustand global store
â”‚           â”œâ”€â”€ useWebSocket.ts            # WS hook
â”‚           â””â”€â”€ utils.ts                  # cn() + helpers
```

---

## Installation

### Quick Start (Docker)

```bash
git clone https://github.com/venkatesh21bit/Nidaan .
cd nidaan

# Minimum: set your Gemini key inside docker-compose.yml
# or copy an .env and edit it:
cp apps/api/.env.example apps/api/.env

docker-compose up -d
docker-compose logs -f api   # watch startup
```

| URL | Service |
|-----|---------|
| http://localhost:3000/patient | Patient voice & chat interface |
| http://localhost:3000/doctor/dashboard | Doctor visit queue |
| http://localhost:3000/admin/dashboard | Admin analytics |
| http://localhost:8000/api/docs | Swagger UI (DEBUG=True) |
| http://localhost:8000/api/redoc | ReDoc |

### Local Development

**Backend:**
```bash
cd apps/api
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
export GEMINI_API_KEY=your_key
export DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/nidaan
uvicorn app.main:app --reload --port 8000
```

**Frontend:**
```bash
cd apps/web
npm install
echo "NEXT_PUBLIC_API_URL=http://localhost:8000/api/v1" > .env.local
npm run dev
```

---

## Demo Accounts

| Role | Email | Password |
|------|-------|----------|
| Doctor | `doctor@nidaan.ai` | `password` |
| Admin | `admin@nidaan.ai` | `admin123` |
| Demo  | `demo@nidaan.ai`  | `demo123`  |

---

## Contributing

1. Fork â†’ `git checkout -b feat/your-feature`
2. Commit â†’ `git commit -m 'feat: describe change'`
3. Push â†’ `git push origin feat/your-feature`
4. Open a pull request

---

## License

MIT â€” see [LICENSE](LICENSE) for details.

---

<div align="center">

**Made in India ğŸ‡®ğŸ‡³ for India**

*Transforming Healthcare Documentation, One Voice at a Time*

</div>
